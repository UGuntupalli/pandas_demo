{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source: https://pandas.pydata.org/pandas-docs/stable/index.html\n",
    "\n",
    "### What is Pandas? \n",
    "Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "### What data structures does Pandas use?\n",
    "Pandas has 2 primary data structures - namely Series(1-D) and DataFrame(2-D). \n",
    "\n",
    "### What to expect from this tutorial/notebook? \n",
    "This tutorial is intended to introduce you to Pandas from a high level and then expose you to\n",
    "- Data Acquisition \n",
    "- Data Cleaning \n",
    "- Data Filtering \n",
    "- Data Aggregation \n",
    "- Data Analysis (depending on time availability)\n",
    "\n",
    "### How is this different from the countless other materials that are publicly available? \n",
    "It is by no means exhaustive or extensive, rather you can consider it my share of learnings that I picked up and learned as I attempted to use Python. I will be sharing tips and tricks that I found to be helpful, but if you know something better, you are welcome to share it with me/us. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to create data-structures in Pandas ? "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os \n",
    "import pickle  \n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0    2\n1    3\n2    5\n3    7\nName: Primes_Under_10, dtype: int64\n0          DesertPy\n1      SoCal_Python\n2    PyLadies_of_LA\nName: Some_Python_Meetups, dtype: object\n0    2\n1    a\n2    4\n3    b\nName: Mixed_Series, dtype: object\n"
    }
   ],
   "source": [
    "# Creating a series \n",
    "my_numeric_series = pd.Series([2, 3, 5, 7], name=\"Primes_Under_10\")\n",
    "print(my_numeric_series)\n",
    "my_character_series = pd.Series([\"DesertPy\", \"SoCal_Python\", \"PyLadies_of_LA\"], name=\"Some_Python_Meetups\")\n",
    "print(my_character_series)\n",
    "my_mixed_series = pd.Series([2, \"a\", 4, \"b\"], name=\"Mixed_Series\")\n",
    "print(my_mixed_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "******************************\nPrinting Dataframe from method 1\n******************************\n           Name       State  Term_Expiry\n0    Doug Ducey     Arizona         2023\n1  Gavin Newsom  California         2023\n2  Ron Desantis     Florida         2023\n3  Andrew Cuomo    New York         2022\n4    Brian Kemp     Georgia         2023\n******************************\nPrinting Dataframe from method 2\n******************************\n           Name           State  Term_Expiry\n0    Jay Inslee      Washington         2021\n1    Ned Lamont     Connecticut         2023\n2  Andy Beshear        Kentucky         2023\n3    Roy Cooper  North Carolina         2021\n******************************\nPrinting Dataframe from method 3\n******************************\n             USA  Brazil  Canada\nState_Count   50      26      10\n******************************\nPrinting Dataframe from method 4\n******************************\n  Stock_Symobl  Dream_Price\n0         AAPL           50\n1         AMZN           10\n2            V            1\n3           MA           78\n******************************\nPrinting Dataframe from method 5\n******************************\n         Place_I_Wanted_To_Be Place_I_Am_At\nJanuary           New Zealand          Home\nFebruary                 Fiji          Home\nMarch                 Bahamas          Home\n"
    }
   ],
   "source": [
    "# Creating a data frame \n",
    "# Method 1 - from list of lists \n",
    "print(\"******************************\")\n",
    "print(\"Printing Dataframe from method 1\")\n",
    "print(\"******************************\")\n",
    "\n",
    "list_of_lists = [[\"Doug Ducey\", \"Arizona\", 2023], [\"Gavin Newsom\", \"California\", 2023], \n",
    "                 [\"Ron Desantis\", \"Florida\", 2023], [\"Andrew Cuomo\", \"New York\", 2022],\n",
    "                 [\"Brian Kemp\", \"Georgia\", 2023]]\n",
    "governors_in_the_news_df = pd.DataFrame(data=list_of_lists, columns=[\"Name\", \"State\", \"Term_Expiry\"])\n",
    "print(governors_in_the_news_df)\n",
    "\n",
    "print(\"******************************\")\n",
    "print(\"Printing Dataframe from method 2\")\n",
    "print(\"******************************\")\n",
    "\n",
    "# Method 2 - from dictionary of lists\n",
    "dict_of_lists = {\"Name\": [\"Jay Inslee\", \"Ned Lamont\", \"Andy Beshear\", \"Roy Cooper\"],\n",
    "                \"State\": [\"Washington\", \"Connecticut\", \"Kentucky\", \"North Carolina\"],\n",
    "                \"Term_Expiry\": [2021, 2023, 2023, 2021]}\n",
    "governors_df = pd.DataFrame(data=dict_of_lists)\n",
    "print(governors_df)\n",
    "\n",
    "print(\"******************************\")\n",
    "print(\"Printing Dataframe from method 3\")\n",
    "print(\"******************************\")\n",
    "\n",
    "# Method 3 - from list of dictionaries \n",
    "list_of_dicts = [{'USA': 50, 'Brazil': 26, 'Canada':10}]\n",
    "states_in_countries_df = pd.DataFrame(data=list_of_dicts, index=[\"State_Count\"])\n",
    "print(states_in_countries_df)\n",
    "\n",
    "print(\"******************************\")\n",
    "print(\"Printing Dataframe from method 4\")\n",
    "print(\"******************************\")\n",
    "\n",
    "# Method 4 - from lists with zip \n",
    "stock_symbols = [\"AAPL\", \"AMZN\", \"V\", \"MA\"]\n",
    "prices_i_wish_i_bought_them_at = [50, 10, 1, 78]\n",
    "stocks_i_wanted_df = pd.DataFrame(data=list(zip(stock_symbols, prices_i_wish_i_bought_them_at)),\n",
    "                                  columns=[\"Stock_Symobl\", \"Dream_Price\"]) \n",
    "print(stocks_i_wanted_df)\n",
    "\n",
    "print(\"******************************\")\n",
    "print(\"Printing Dataframe from method 5\")\n",
    "print(\"******************************\")\n",
    "\n",
    "# Method 5 - dict of pd.Series \n",
    "dict_of_series = {'Place_I_Wanted_To_Be' : \n",
    "                    pd.Series([\"New Zealand\", \"Fiji\", \"Bahamas\"], index =[\"January\",    \"February\", \"March\"]),                  'Place_I_Am_At' : \n",
    "                    pd.Series([\"Home\", \"Home\", \"Home\"], index =[\"January\", \"February\", \"March\"])} \n",
    "lockdown_mood_df = pd.DataFrame(dict_of_series)\n",
    "print(lockdown_mood_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways-1\n",
    "#### From the above examples, it is helpful to identify a few takeaways: \n",
    "- Series and DataFrame can represent most of the commonly used data sets. Constructing your data into a Series or a DataFrame allows you to leverage a lot of built-in functionality that Pandas offers \n",
    "- Series and DataFrame support homogeneous and heterogeneous data - meaning they can handle same data types as well as different data types \n",
    "- Series and DataFrame have an index property which defaults to an integer but can be set as desired (imagine time stamps, letters etc.)\n",
    "- Pandas 1.0.0 deprecated the testing module and limited to only assertion functions. While not advisable, if you are using a version < 1.0.0, pandas.util.testing offers close to 30 different built-in functions to whip up different data frames that make it easy to test. You can get the list of possible functions like so \n",
    "\n",
    "```\n",
    "import pandas.util.testing as tm \n",
    "dataframe_constructor_functions = [i for i in dir(tm) if i.startswith('make')]\n",
    "print(dataframe_constructor_functions)\n",
    "```\n",
    "\n",
    "- While all of these are good to know, a typical use-case would not require a user to create data, rather import/acquire data from several different data sources - which leads us to our first topic of Data Acquisition "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition \n",
    "\n",
    "#### One of the most powerful and appealing aspects of Pandas is its ability to easily acquire and ingest data from several different data sources including but not limited to: \n",
    "- CSV\n",
    "- Text \n",
    "- JSON \n",
    "- HTML \n",
    "- Excel\n",
    "- SQL\n",
    "\n",
    "  An exhaustive list can be found here - https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "******************************\nPrinting Dataframe from CSV\n******************************\n  Province/State Country/Region      Lat     Long  1/22/20  1/23/20  1/24/20  \\\n0            NaN    Afghanistan  33.0000  65.0000        0        0        0   \n1            NaN        Albania  41.1533  20.1683        0        0        0   \n2            NaN        Algeria  28.0339   1.6596        0        0        0   \n3            NaN        Andorra  42.5063   1.5218        0        0        0   \n4            NaN         Angola -11.2027  17.8739        0        0        0   \n\n   1/25/20  1/26/20  1/27/20  ...  3/24/20  3/25/20  3/26/20  3/27/20  \\\n0        0        0        0  ...       74       84       94      110   \n1        0        0        0  ...      123      146      174      186   \n2        0        0        0  ...      264      302      367      409   \n3        0        0        0  ...      164      188      224      267   \n4        0        0        0  ...        3        3        4        4   \n\n   3/28/20  3/29/20  3/30/20  3/31/20  4/1/20  4/2/20  \n0      110      120      170      174     237     273  \n1      197      212      223      243     259     277  \n2      454      511      584      716     847     986  \n3      308      334      370      376     390     428  \n4        5        7        7        7       8       8  \n\n[5 rows x 76 columns]\n******************************\nPrinting Dataframe from JSON\n******************************\n  city  trips       date  value  price request_date   medium  %price   type  \\\n0   ab      4 2014-01-25    4.7    1.1   2014-06-17   iPhone    15.4   True   \n1   bc      0 2014-01-29    5.0    1.0   2014-05-05  Android     0.0  False   \n\n   Weekly_pct  avg_dist  avg_price  weekly_pct  \n0        46.2      3.67          5         NaN  \n1         NaN      8.26          5        50.0  \n******************************\nPrinting Dataframe from Excel\n******************************\n  Province/State Country/Region      Lat     Long  2020-01-22 00:00:00  \\\n0            NaN    Afghanistan  33.0000  65.0000                    0   \n1            NaN        Albania  41.1533  20.1683                    0   \n2            NaN        Algeria  28.0339   1.6596                    0   \n3            NaN        Andorra  42.5063   1.5218                    0   \n4            NaN         Angola -11.2027  17.8739                    0   \n\n   2020-01-23 00:00:00  2020-01-24 00:00:00  2020-01-25 00:00:00  \\\n0                    0                    0                    0   \n1                    0                    0                    0   \n2                    0                    0                    0   \n3                    0                    0                    0   \n4                    0                    0                    0   \n\n   2020-01-26 00:00:00  2020-01-27 00:00:00  ...  2020-03-24 00:00:00  \\\n0                    0                    0  ...                    1   \n1                    0                    0  ...                   10   \n2                    0                    0  ...                   24   \n3                    0                    0  ...                    1   \n4                    0                    0  ...                    0   \n\n   2020-03-25 00:00:00  2020-03-26 00:00:00  2020-03-27 00:00:00  \\\n0                    2                    2                    2   \n1                   17                   17                   31   \n2                   65                   29                   29   \n3                    1                    1                    1   \n4                    0                    0                    0   \n\n   2020-03-28 00:00:00  2020-03-29 00:00:00  2020-03-30 00:00:00  \\\n0                    2                    2                    2   \n1                   31                   33                   44   \n2                   31                   31                   37   \n3                    1                    1                   10   \n4                    0                    0                    0   \n\n   2020-03-31 00:00:00  2020-04-01 00:00:00  2020-04-02 00:00:00  \n0                    5                    5                   10  \n1                   52                   67                   76  \n2                   46                   61                   61  \n3                   10                   10                   10  \n4                    1                    1                    1  \n\n[5 rows x 76 columns]\n"
    }
   ],
   "source": [
    "# CSV \n",
    "print(\"******************************\")\n",
    "print(\"Printing Dataframe from CSV\")\n",
    "print(\"******************************\")\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "confimed_global_cases_file_path = os.path.join(current_directory, \"covid-19_data\",\"time_series_covid19_confirmed_global.csv\") \n",
    "confirmed_global_cases_df = pd.read_csv(filepath_or_buffer=confimed_global_cases_file_path) \n",
    "print(confirmed_global_cases_df.head()) \n",
    "\n",
    "# JSON \n",
    "print(\"******************************\")\n",
    "print(\"Printing Dataframe from JSON\")\n",
    "print(\"******************************\")\n",
    "json_file_path = os.path.join(current_directory, \"sample_json.json\")\n",
    "json_df = pd.read_json(json_file_path)\n",
    "print(json_df)\n",
    "\n",
    "# Excel\n",
    "print(\"******************************\")\n",
    "print(\"Printing Dataframe from Excel\")\n",
    "print(\"******************************\")\n",
    "# excel_file_path = os.path.join(current_directory, \"covid-19_data\",\"time_series_covid19_confirmed_recovered.xlsx\")\n",
    "os.chdir(\"covid-19_data\")\n",
    "recovered_global_cases_df = pd.read_excel(\"time_series_covid19_recovered_global.xlsx\")\n",
    "os.chdir(current_directory)\n",
    "print(recovered_global_cases_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways-2\n",
    "\n",
    "#### Based on the few limited examples above: \n",
    "- Pandas has several robust i/o parsers which makes it really easy to consume data from several different sources \n",
    "- If you are going to work with pandas, it is best to use pandas to acquire the data, as long as parser exists because they are optimized to handle large sets of data \n",
    "- What would have been a great example would be to consume SQL data, but since I don't have enough power on my machine to install a SQL Server program, I am forced to skip that - if you have access to a database, do try and consume data from the database. You would be needing either pyodbc or sqlalchemy or a similar package as a wrapper. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning  & Data Filtering (They are quite intertwined)\n",
    "\n",
    "#### Messy (or) Unorganized data is very common. Even if the data is organized and logically makes sense, it might have missing data or NaN's or NA's which could be a hindrance to smooth analysis of your data. \n",
    "\n",
    "### Tip #1 - If you are going to modify a data frame and want the original data, create a copy "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By copying a dataframe with deep flag turned on, a new data frame is created including a copy of the data and the indices. \n",
    "# Changes made to this new data frame are not reflected in the original data frame object and vice-versa \n",
    "confirmed_global_cases_copy_df = confirmed_global_cases_df.copy(deep=True)\n",
    "\n",
    "# Let us we want to only look at countries where there is state/province-level data available \n",
    "confirmed_global_cases_copy_df = confirmed_global_cases_copy_df[confirmed_global_cases_copy_df[\"Province/State\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the data frame index does not hold any special order now and it does not convey any meaning by itself, unless we reference it or compare with the original data frame. We can fix that by re-setting the index \n",
    "confirmed_global_cases_copy_df = confirmed_global_cases_copy_df.reset_index(drop=True) \n",
    "# drop flag prevents the column from being added back to the dataframe as a new column. also remember to assign the data frame back to your variable. resetting of index, returns an object and unless we capture it and re-assign to the same variable, the change is lost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us say, we only want countries in the Northern Hemisphere \n",
    "def hemisphere_flag(df):\n",
    "    if (df[\"Lat\"] >= 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "confirmed_global_cases_copy_df[\"Northern_Hemisphere_Flag\"] = confirmed_global_cases_copy_df.apply(hemisphere_flag, axis=1)\n",
    "northern_hemisphere_confirmed_cases_df = confirmed_global_cases_copy_df[confirmed_global_cases_copy_df[\"Northern_Hemisphere_Flag\"] == 1]\n",
    "northern_hemisphere_confirmed_cases_df = northern_hemisphere_confirmed_cases_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}